<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aether's Blog</title>
    <description>Keep calm and carry on # this means to ignore newlines until &quot;baseurl:&quot;
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 09 Mar 2020 10:21:37 +0800</pubDate>
    <lastBuildDate>Mon, 09 Mar 2020 10:21:37 +0800</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>《非暴力沟通》读书笔记</title>
        <description>&lt;p&gt;非暴力沟通的四个要素：&lt;strong&gt;观察&lt;/strong&gt;、&lt;strong&gt;感受&lt;/strong&gt;、&lt;strong&gt;需要&lt;/strong&gt;、&lt;strong&gt;请求&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;关于道德评价&quot;&gt;关于道德评价&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;对他人的评价实际上反映了我们的需要和价值观。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;不要将&lt;strong&gt;价值判断&lt;/strong&gt;与&lt;strong&gt;道德评判&lt;/strong&gt;混为一谈——对于不符合个人价值观的行为，表达主观态度是比评判与批评更妥当的行为。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;暴力的根源在于人们忽视彼此的感受与需要，而将冲突归咎于对方——至少大部分暴力的根源都是如此&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;关于责任&quot;&gt;关于责任&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;用负责任的语言代替回避责任的语言。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;“have to … ”的表达淡化了个人责任、“you made me … ”的表达忽视内在的情感根源。直视自己的责任和情感，才能意识自己对自己的思想、情感和行动负有责任，自己才是生活的主人。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“我常常想，如果有一天，技术的进步最终被用来摧毁人类，那么，并非是暴行导致人类的灭亡，当然，更不能说是复仇行为使人类灭亡……人类的灭亡，却是因为现代人唯唯诺诺、缺乏责任感，毕恭毕敬地服从各种命令。我们所看到的悲剧和马上就要看到的更大悲剧，并非是世界上反抗的人、不服从的人增多了，而是唯命是从的人、听话的人越来越多。”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;观察&quot;&gt;观察&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;非暴力沟通的第一个要素是观察。将观察和评论混为一谈，别人就会倾向于听到批评，并反驳我们。非暴力沟通是&lt;strong&gt;动态的语言&lt;/strong&gt;，不主张绝对化的结论。它提倡在特定的时间和情境中进行观察，并清楚地描述观察结果。例如，它会说“欧文在过去的5场比赛中没有进一个球”，而不是说“欧文是个差劲的前锋”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;区分观察和评论&lt;/strong&gt;：观察即实际发生的情况，是不掺杂个人情感的客观描述，更易被对方接受。所以清楚地表达观察结果，而不判断或评估可以避免批评带来的反作用。&lt;/p&gt;

&lt;h2 id=&quot;感受&quot;&gt;感受&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;非暴力沟通的第二个要素是感受。通过建立表达感受的词汇表，我们可以更清楚地表达感受，从而使沟通更为顺畅。在表达感受时，示弱有助于解决冲突。此外，非暴力沟通还对表达具体感受的词语与陈述想法、评论以及观点的词语作了区分。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;区分感受与想法&lt;/strong&gt;——感受即“feel”，是个人情感的描述。而想法为“think of”，包含着评判的意味。对于很多的“我觉得”，本质上不是感受，而是想法。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;听到不中听的话的四种选择：&lt;/p&gt;

  &lt;p&gt;1．责备自己&lt;/p&gt;

  &lt;p&gt;2．指责他人&lt;/p&gt;

  &lt;p&gt;3．体会自己的感受和需要&lt;/p&gt;

  &lt;p&gt;4．体会他人的感受和需要&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;甲：你昨晚没来令我很失望。&lt;/p&gt;

  &lt;p&gt;乙：昨晚你没来，我很失望，因为我想和你说一些烦心事。&lt;/p&gt;

  &lt;p&gt;在上面的例句中，甲认为，她的感受是由他人的行为引起的。而乙认为，她感到失望，是因为她的愿望没有得到满足。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果我们想利用他人的内疚，我们通常采取的办法是，把自己不愉快的感受归咎于对方。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;非暴力沟通强调&lt;strong&gt;感受的根源在于自身&lt;/strong&gt;。我们的需要和期待，以及对他人言行的看法，导致了我们的感受。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;批评往往暗含着期待。对他人的批评实际上间接表达了我们尚未满足的需要。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果我们通过批评来提出主张，人们的反应常常是申辩或反击。反之，如果我们直接说出需要，其他人就较有可能作出积极的回应。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;对于主观上不喜欢听的言论怀有抗拒和逃避的情绪是人的本能。在沟通中，可以思考是否可以用&lt;strong&gt;直接表达批评暗含的需求&lt;/strong&gt;来替代批评。&lt;/p&gt;
</description>
        <pubDate>Sun, 02 Feb 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/reading/%E9%9D%9E%E6%9A%B4%E5%8A%9B%E6%B2%9F%E9%80%9A-%E6%80%BB%E7%BB%93.html</link>
        <guid isPermaLink="true">http://localhost:4000/reading/%E9%9D%9E%E6%9A%B4%E5%8A%9B%E6%B2%9F%E9%80%9A-%E6%80%BB%E7%BB%93.html</guid>
        
        <category>reading</category>
        
        
        <category>reading</category>
        
      </item>
    
      <item>
        <title>《弱传播》读书笔记</title>
        <description>&lt;p&gt;《弱传播》一书试图像牛顿总结物理世界的运动定律一般，去构建舆论世界的完整体系。&lt;/p&gt;
</description>
        <pubDate>Sun, 02 Feb 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/reading/%E5%BC%B1%E4%BC%A0%E6%92%AD-%E6%80%BB%E7%BB%93.html</link>
        <guid isPermaLink="true">http://localhost:4000/reading/%E5%BC%B1%E4%BC%A0%E6%92%AD-%E6%80%BB%E7%BB%93.html</guid>
        
        <category>reading</category>
        
        
        <category>reading</category>
        
      </item>
    
      <item>
        <title>非考试向计算机网络知识总结</title>
        <description>&lt;h2 id=&quot;计算机网络模型&quot;&gt;计算机网络模型&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;OSI参考模型&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;五层参考模型&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;应用层&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;应用层&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;表示层&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;传输层&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;会话层&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;网络层&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;传输层&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;数据链路层&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;网络层&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;物理层&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;数据链路层&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;物理层&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;网络应用层&quot;&gt;网络应用层&lt;/h2&gt;

&lt;h3 id=&quot;网络应用的体系结构&quot;&gt;网络应用的体系结构&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;客户机/服务器结构&lt;/strong&gt;(Client-Server, &lt;strong&gt;C/S&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;点对点结构&lt;/strong&gt;(Peer-to-peer, &lt;strong&gt;P2P&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;混合结构&lt;/strong&gt;(Hybrid)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;http协议--hypertext-transfer-protocol&quot;&gt;HTTP协议 —— HyperText Transfer Protocol&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;C/S结构&lt;/strong&gt; Client — Server&lt;/li&gt;
  &lt;li&gt;HTTP版本：1.0、1.1&lt;/li&gt;
  &lt;li&gt;使用TCP传输服务&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;无状态&lt;/strong&gt;(stateless)：服务器不维护任何有关客户端过去所发请求的信息&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HTTP连接的两种类型&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;非持久性连接&lt;/strong&gt;(Nonpersistent HTTP)
        &lt;ul&gt;
          &lt;li&gt;每个TCP连接最多允许传输一个对象&lt;/li&gt;
          &lt;li&gt;HTTP 1.0版本使用非持久性连接&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;持久性连接&lt;/strong&gt;(Persistent HTTP)
        &lt;ul&gt;
          &lt;li&gt;每个TCP连接允许传输多个对象&lt;/li&gt;
          &lt;li&gt;HTTP 1.1版本默认使用持久性连接&lt;/li&gt;
          &lt;li&gt;带有流水机制的持久性连接&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;email应用&quot;&gt;Email应用&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;SMTP协议&lt;/strong&gt; (简单邮件传输协议 Simple Mail Transfer user agent Protocol)&lt;/li&gt;
  &lt;li&gt;邮件访问协议 - 从服务器获取邮件
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;POP&lt;/strong&gt;: Post Office Protocol [RFC 1939]&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;IMAP&lt;/strong&gt;: Internet Mail Access Protocol [RFC 1730]&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;HTTP&lt;/strong&gt;:163, QQ Mail等。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dns应用&quot;&gt;DNS应用&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;域名 –&amp;gt; IP地址&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;主机别名&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;负载均衡&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;分布式&lt;/strong&gt;+&lt;strong&gt;层次式&lt;/strong&gt;结构：
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;根域名服务器&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;顶级域名服务器&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Network Solution维护com顶级域名服务器&lt;/li&gt;
          &lt;li&gt;Educause维护edu顶级域名服务器&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;权威域名服务器&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;本地域名解析服务器&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;DNS查询：&lt;strong&gt;迭代查询&lt;/strong&gt;/&lt;strong&gt;递归查询&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;传输层&quot;&gt;传输层&lt;/h2&gt;

&lt;p&gt;传输层协议为&lt;strong&gt;运行在不同主机上的进程&lt;/strong&gt;提供了一种&lt;strong&gt;逻辑通信机制&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;可靠、按序的交付服务 —— TCP&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;拥塞控制、流量控制、连接建立&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;不可靠的交付服务 —— &lt;strong&gt;UDP&lt;/strong&gt; (User Datagram Protocol)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;基于Internet IP协议：&lt;strong&gt;多路复用/多路分用&lt;/strong&gt;、简单的&lt;strong&gt;错误校验&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;“Best effort”服务：UDP段可能&lt;strong&gt;丢失&lt;/strong&gt;、&lt;strong&gt;非按序&lt;/strong&gt;到达&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;无连接&lt;/strong&gt;：UDP发送方和接收方之间&lt;em&gt;不需要握手&lt;/em&gt;、每个UDP段的处理&lt;strong&gt;独立&lt;/strong&gt;于其他段&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;用途：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;常用于&lt;strong&gt;流媒体应用&lt;/strong&gt;：容忍丢失、速率敏感&lt;/li&gt;
      &lt;li&gt;用于&lt;strong&gt;DNS&lt;/strong&gt;、SNMP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;滑动窗口协议&quot;&gt;滑动窗口协议&lt;/h3&gt;

&lt;p&gt;滑动窗口协议:GBN, SR&lt;/p&gt;

&lt;h3 id=&quot;拥塞控制原理&quot;&gt;拥塞控制原理&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;拥塞：&lt;strong&gt;分组丢失&lt;/strong&gt;(路由器缓存溢出)、&lt;strong&gt;分组延迟过大&lt;/strong&gt;(在路由器缓存中排队)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;拥塞控制vs流量控制：流量控制：端—端；拥塞控制：网络整体&lt;/li&gt;
  &lt;li&gt;拥塞控制的方法
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;端到端拥塞控制&lt;/strong&gt;：网络层不需要显式的提供支持，端系统通过观察loss，delay等网络行为判断是否发生拥塞来控制发送速率。TCP采取这种方法&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;网络辅助的拥塞控制&lt;/strong&gt;：路由器向发送方显式地反馈网络拥塞信息指示发送方应该采取何种速率&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tcp拥塞控制&quot;&gt;TCP拥塞控制&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;感知网络拥塞：Loss事件=timeout / 3个重复 ACK。发生loss事件后，发送方降低速率
    &lt;ul&gt;
      &lt;li&gt;3个重复ACKs：CongWin减半后线性增长 —— 拥塞不太严重，还有传输segments的能力&lt;/li&gt;
      &lt;li&gt;Timeout事件： CongWin直接设为1个MSS后指数增长，达到threshold后, 再线性增长 —— 拥塞更严重&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;调整发送速率策略&quot;&gt;调整发送速率策略：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;加性增—乘性减: AIMD
    &lt;ul&gt;
      &lt;li&gt;逐渐增加发送速率，谨慎探测可用带宽，直到发生loss&lt;/li&gt;
      &lt;li&gt;AI——Additive Increase: 每个RTT将CongWin增大一个MSS——拥塞避免&lt;/li&gt;
      &lt;li&gt;MD —— Decrease: 发生loss后将CongWin减半&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;慢启动: SS
    &lt;ul&gt;
      &lt;li&gt;当连接开始时，CongWin指数性增长&lt;/li&gt;
      &lt;li&gt;Threshold = CongWin达到Loss时的1/2，当CongWin达到Threshold时变为线性增长&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tcp流量控制&quot;&gt;TCP流量控制&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;接收方为TCP连接分配buffer，上层应用可能处理buffer中数据的速度较慢，流量控制使发送方不会传输的太多、太快以至于淹没接收方 (buffer溢出)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;速度匹配&lt;/strong&gt;机制&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tcp三次握手四次挥手&quot;&gt;TCP三次握手四次挥手&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;三次握手&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;客户端发送&lt;strong&gt;SYN&lt;/strong&gt;报文段
        &lt;ul&gt;
          &lt;li&gt;不携带数据&lt;/li&gt;
          &lt;li&gt;SYN标志位置1&lt;/li&gt;
          &lt;li&gt;选择初始序列号&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;服务器接受&lt;strong&gt;SYN&lt;/strong&gt;，回复&lt;strong&gt;SYNACK&lt;/strong&gt;报文段
        &lt;ul&gt;
          &lt;li&gt;分配缓存&lt;/li&gt;
          &lt;li&gt;确定初始序列号&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;客户端接受&lt;strong&gt;SYNACK&lt;/strong&gt;，回复&lt;strong&gt;ACK&lt;/strong&gt;报文段，SYN标志位不为1，开始传输数据&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;关闭连接&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;客户端关闭socket&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;client向server发送TCP &lt;strong&gt;FIN&lt;/strong&gt; 控制segment&lt;/li&gt;
      &lt;li&gt;server &lt;strong&gt;收到FIN&lt;/strong&gt;, &lt;strong&gt;回复ACK&lt;/strong&gt;. &lt;strong&gt;关闭连接&lt;/strong&gt;, &lt;strong&gt;发送 FIN&lt;/strong&gt;.&lt;/li&gt;
      &lt;li&gt;client &lt;strong&gt;收到FIN, 回复ACK&lt;/strong&gt;.
        &lt;ul&gt;
          &lt;li&gt;进入等待 —— 如果&lt;strong&gt;收到FIN&lt;/strong&gt;，会&lt;strong&gt;重新发送ACK&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;server&lt;strong&gt;收到ACK. 连接关闭&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;网络层&quot;&gt;网络层&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;网络层&lt;/strong&gt;:提供&lt;strong&gt;主机之间&lt;/strong&gt;的逻辑通信机制&lt;/p&gt;

&lt;h3 id=&quot;网络层核心功能&quot;&gt;网络层核心功能&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;转发与路由&lt;/li&gt;
  &lt;li&gt;连接建立&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;网络层服务模型&quot;&gt;网络层服务模型&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;无连接服务&lt;/strong&gt;(connection-less service):
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;数据报网络&lt;/strong&gt;(datagram network) 分组交换&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;连接服务&lt;/strong&gt;(connection service)
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;虚电路网络&lt;/strong&gt;(virtual-circuit network) 分组交换&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;有类ip地址&quot;&gt;有类IP地址&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;A类地址&lt;/td&gt;
      &lt;td&gt;NetID(8位) + HostID(24位)&lt;/td&gt;
      &lt;td&gt;0****&lt;/td&gt;
      &lt;td&gt;0.0.0.0~127.255.255.255&lt;/td&gt;
      &lt;td&gt;50%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;B类地址&lt;/td&gt;
      &lt;td&gt;NetID(16位) HostID(16位)&lt;/td&gt;
      &lt;td&gt;10***&lt;/td&gt;
      &lt;td&gt;128.0.0.0~191.255.255.255&lt;/td&gt;
      &lt;td&gt;25%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;C类地址&lt;/td&gt;
      &lt;td&gt;NetID(24位) HostID(8位)&lt;/td&gt;
      &lt;td&gt;110**&lt;/td&gt;
      &lt;td&gt;192.0.0.0~223.255.255.255&lt;/td&gt;
      &lt;td&gt;12.5%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;D类地址&lt;/td&gt;
      &lt;td&gt;NetID(24位) HostID(8位)&lt;/td&gt;
      &lt;td&gt;1110*&lt;/td&gt;
      &lt;td&gt;224.0.0.0~239.255.255.255&lt;/td&gt;
      &lt;td&gt;6.25%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;E类地址&lt;/td&gt;
      &lt;td&gt;NetID(24位) HostID(8位)&lt;/td&gt;
      &lt;td&gt;1111*&lt;/td&gt;
      &lt;td&gt;240.0.0.0~255.255.255.255&lt;/td&gt;
      &lt;td&gt;6.25%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;特殊ip地址&quot;&gt;特殊IP地址&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;NetID&lt;/th&gt;
      &lt;th&gt;HostID&lt;/th&gt;
      &lt;th&gt;IP分组源地址&lt;/th&gt;
      &lt;th&gt;IP分组目的地址&lt;/th&gt;
      &lt;th&gt;用途&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;全0&lt;/td&gt;
      &lt;td&gt;全0&lt;/td&gt;
      &lt;td&gt;可以&lt;/td&gt;
      &lt;td&gt;不可以&lt;/td&gt;
      &lt;td&gt;在本网范围内表示本机;在路由表中用于表示默认路由 (相当于表示整个Internet网络)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;全0&lt;/td&gt;
      &lt;td&gt;特定值&lt;/td&gt;
      &lt;td&gt;不可以&lt;/td&gt;
      &lt;td&gt;可以&lt;/td&gt;
      &lt;td&gt;表示本网内某个特定主机 0.0.0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;全1&lt;/td&gt;
      &lt;td&gt;全1&lt;/td&gt;
      &lt;td&gt;不可以&lt;/td&gt;
      &lt;td&gt;可以&lt;/td&gt;
      &lt;td&gt;本网广播地址(路由器不转发) 255.255.255.255&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;特定值&lt;/td&gt;
      &lt;td&gt;全0&lt;/td&gt;
      &lt;td&gt;不可以&lt;/td&gt;
      &lt;td&gt;不可以&lt;/td&gt;
      &lt;td&gt;网络地址，表示一个网络&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;特定值&lt;/td&gt;
      &lt;td&gt;全1&lt;/td&gt;
      &lt;td&gt;不可以&lt;/td&gt;
      &lt;td&gt;可以&lt;/td&gt;
      &lt;td&gt;直接广播地址，对特定网络上的所有主机进行广播&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;127&lt;/td&gt;
      &lt;td&gt;非全0或非全1的 任何数&lt;/td&gt;
      &lt;td&gt;可以&lt;/td&gt;
      &lt;td&gt;可以&lt;/td&gt;
      &lt;td&gt;用于本地软件环回测试，称为环回地址&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;私有地址&quot;&gt;私有地址&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Class&lt;/th&gt;
      &lt;th&gt;NetIDs&lt;/th&gt;
      &lt;th&gt;Blocks&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;172.16 to 172.31&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;192.168.0 to 192.168.255&lt;/td&gt;
      &lt;td&gt;256&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;cidr与路由聚合&quot;&gt;CIDR与路由聚合&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;无类域间路由(CIDR: Classless InterDomain Routing)&lt;/li&gt;
  &lt;li&gt;消除传统的 A 类、B 类和 C 类地址界限
    &lt;ul&gt;
      &lt;li&gt;NetID+SubID→Network Prefix (Prefix)可以任意长度&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;融合子网地址与子网掩码，方便子网划分
    &lt;ul&gt;
      &lt;li&gt;无类地址格式:a.b.c.d/x，其中x为前缀长度&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dhcp协议&quot;&gt;DHCP协议&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;主机获取IP地址方式：
    &lt;ul&gt;
      &lt;li&gt;“硬编码” —— 静态配置&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;动态主机配置协议&lt;/strong&gt; —— DHCP: Dynamic Host ConfigurationProtocol
        &lt;ul&gt;
          &lt;li&gt;从服务器动态获取IP地址、子网掩码、默认网关地址、DNS服务器名称与IP地址&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;DHCP特点
    &lt;ul&gt;
      &lt;li&gt;“即插即用”&lt;/li&gt;
      &lt;li&gt;允许地址重用&lt;/li&gt;
      &lt;li&gt;支持在用地址续租&lt;/li&gt;
      &lt;li&gt;支持移动用户加入网络&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;DHCP工作过程
    &lt;ul&gt;
      &lt;li&gt;主机广播 “DHCP discover”(发现报文)&lt;/li&gt;
      &lt;li&gt;DHCP服务器利用 “DHCP offer” (提供报文) 进行响应&lt;/li&gt;
      &lt;li&gt;主机请求IP地址: “DHCP request” (请求报文)&lt;/li&gt;
      &lt;li&gt;DHCP服务器分配IP地址: “DHCP ack” (确认报文)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;DHCP协议在&lt;strong&gt;应用层&lt;/strong&gt;实现→请求报文封装到&lt;strong&gt;UDP数据报&lt;/strong&gt;中→IP广播→链路层广播(e.g. 以太网广播)&lt;/li&gt;
  &lt;li&gt;DHCP服务器构造ACK报文：包括分配给客户的IP地址、子网掩码 、默认网关、DNS 服务器地址&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nat&quot;&gt;NAT&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;网络地址转换&lt;/strong&gt;(NAT)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;本地网络&lt;/strong&gt;内通信的IP数据报的源与目的IP地址均在子网&lt;strong&gt;10.0.0/24&lt;/strong&gt;内，所有离开本地网络去往 Internet的数据报的&lt;strong&gt;源IP地址&lt;/strong&gt;需替换为&lt;strong&gt;相同的NAT IP地址&lt;/strong&gt;: 138.76.29.7以及不同的端口号&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;优点&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;只需/能从ISP申请一个IP地址（IPv4地址耗尽）&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;本地网络设备全部使用私有地址，IP地址的变更无需通告外界网络&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;变更ISP时，无需修改内部网络设备IP地址&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;内部网络设备对外界网络不可见，即不可直接寻址(安全)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;icmp&quot;&gt;ICMP&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;互联网控制报文协议&lt;/strong&gt;(ICMP)支持主机或路由器差错(或异常)报告+网络探询&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ICMP 报文类型&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;差错报告报文&lt;/strong&gt;(5种)
        &lt;ul&gt;
          &lt;li&gt;目的不可达&lt;/li&gt;
          &lt;li&gt;源抑制(Source Quench) 拥塞控制&lt;/li&gt;
          &lt;li&gt;超时/超期(TTL)&lt;/li&gt;
          &lt;li&gt;参数问题&lt;/li&gt;
          &lt;li&gt;重定向 (Redirect)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;网络探询报文&lt;/strong&gt;(2组)
        &lt;ul&gt;
          &lt;li&gt;回声(Echo)请求与应答报文(Reply)  —— &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;时间戳请求与应答报文&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;几种不发送 ICMP差错报告报文的特殊情况:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;对ICMP差错报告报文不再发送 ICMP差错报告报文&lt;/li&gt;
      &lt;li&gt;除第1个IP数据报分片外，对所有后续分片均不发送ICMP差错 报告报文&lt;/li&gt;
      &lt;li&gt;对所有&lt;strong&gt;多播IP数据报&lt;/strong&gt;均不发送 ICMP差错报告报文&lt;/li&gt;
      &lt;li&gt;对具有&lt;strong&gt;特殊地址&lt;/strong&gt;(如127.0.0.0 或 0.0.0.0)的IP数据报不发送ICMP差错报告报文&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ICMP报文的格式&lt;/p&gt;

    &lt;p&gt;ICMP报文&lt;strong&gt;封装到IP数据报&lt;/strong&gt;中传输&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;数据链路层&quot;&gt;数据链路层&lt;/h2&gt;

&lt;p&gt;主机和路由器：结点&lt;/p&gt;

&lt;p&gt;连接相邻结点的通信信道：链路  包括有线链路、无限链路、局域网&lt;/p&gt;

&lt;p&gt;数据链路层负责通过一条链路从一个节点向另一个物理链路直接相连的相邻结点传送数据报。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;组帧(framing)
    &lt;ul&gt;
      &lt;li&gt;加首部尾部 将&lt;strong&gt;数据报&lt;/strong&gt;组装为&lt;strong&gt;帧&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;帧同步&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;链路接入(link access)：帧首部中的“MAC”地址，用于标识帧的源和目的&lt;/li&gt;
  &lt;li&gt;相邻结点间&lt;strong&gt;可靠&lt;/strong&gt;交付&lt;/li&gt;
  &lt;li&gt;流量控制(flow control)&lt;/li&gt;
  &lt;li&gt;差错检测(error detection)：通知发送端重传或者直接丢弃帧&lt;/li&gt;
  &lt;li&gt;差错纠正(error correction) ：接收端直接纠正比特差错&lt;/li&gt;
  &lt;li&gt;全双工和半双工通信控制
    &lt;ul&gt;
      &lt;li&gt;全双工:链路两端结点同时双向传输&lt;/li&gt;
      &lt;li&gt;半双工:链路两端结点交替双向传输&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;多路访问控制mac协议&quot;&gt;多路访问控制(MAC)协议&lt;/h3&gt;

&lt;p&gt;两类“链路”：点对点链路、广播链路 (共享介质)&lt;/p&gt;

&lt;p&gt;两个或者两个以上结点同时传输发生&lt;strong&gt;冲突&lt;/strong&gt;(collision)&lt;/p&gt;

&lt;p&gt;MAC协议采用&lt;strong&gt;分布式算法&lt;/strong&gt;决定结点如何共享信道，即决策结点何时可以传输数据&lt;/p&gt;

&lt;p&gt;MAC协议分类&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;信道划分&lt;/strong&gt;(channel partitioning)MAC协议
    &lt;ul&gt;
      &lt;li&gt;多路复用技术&lt;/li&gt;
      &lt;li&gt;TDMA：“周期性”接入信道，每个站点在每个周期，占用固定长度的时隙&lt;/li&gt;
      &lt;li&gt;FDMA：信道频谱划分为若干频带(frequency bands)，每个站点分配一个固定的频带，无传输频带空闲&lt;/li&gt;
      &lt;li&gt;CDMA、WDMA等&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;随机访问&lt;/strong&gt;(random access)MAC协议
    &lt;ul&gt;
      &lt;li&gt;信道不划分，允许&lt;strong&gt;冲突&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;采用冲突“&lt;strong&gt;恢复&lt;/strong&gt;”机制&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;轮转&lt;/strong&gt;(“taking turns”)MAC协议
    &lt;ul&gt;
      &lt;li&gt;结点轮流使用信道&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;arp协议&quot;&gt;ARP协议&lt;/h3&gt;

&lt;p&gt;LAN中的每个IP结点维护&lt;strong&gt;ARP表&lt;/strong&gt;，储存某些LAN结点的IP/MAC地址映射关系&amp;lt;IP,MAC,TTL&amp;gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 02 Feb 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/note/%E9%9D%9E%E8%80%83%E8%AF%95%E5%90%91%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93.html</link>
        <guid isPermaLink="true">http://localhost:4000/note/%E9%9D%9E%E8%80%83%E8%AF%95%E5%90%91%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93.html</guid>
        
        
        <category>note</category>
        
      </item>
    
      <item>
        <title>What is Block Chain?</title>
        <description>&lt;h2 id=&quot;什么是区块链&quot;&gt;什么是区块链？&lt;/h2&gt;

&lt;p&gt;常规的交易体系是&lt;strong&gt;中心化&lt;/strong&gt;的，买家、卖家围绕着银行进行交易。在享受银行提供的安全保护以及各种便利服务的同时，也意味着我们被&lt;strong&gt;监管&lt;/strong&gt;。那么是否有办法避开银行这个交易中心，使交易只在&lt;strong&gt;点对点之间&lt;/strong&gt;展开呢？&lt;/p&gt;

&lt;p&gt;区块币创始人中本聪使用分布式的思想提出了一种&lt;strong&gt;去中心化&lt;/strong&gt;的交易体系：参与到交易系统中的人都维护一份账本，记录系统中的每一笔交易，产生分歧时多数账本认可的就是系统的权威。&lt;/p&gt;

&lt;p&gt;人民日报对于区块链作出了这样的比喻：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;你家里有个账本，你一人来记帐，爸爸妈妈把工资交给你，你记到账本上，中间万一你贪吃，想买点好吃的，可能账本上的记录会少十几块。&lt;/p&gt;

  &lt;p&gt;利用区块链技术之后，你在记帐，爸爸也在记账，妈妈也在记账，他们都能看到总帐，你不能改，爸爸妈妈也不能改。这样想买烟抽的爸爸贪吃的你都没办法啦。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;也就是说，区块链这个分布式数字账本记录了所有曾经发生并经过系统一致认可的交易。每个&lt;strong&gt;区块&lt;/strong&gt;就是一个账本。&lt;/p&gt;

&lt;h3 id=&quot;如何快速对账&quot;&gt;如何快速对账？&lt;/h3&gt;

&lt;p&gt;直接比对区块值运算量巨大，将区块&lt;strong&gt;Hash&lt;/strong&gt;后比较即可。&lt;/p&gt;

&lt;h3 id=&quot;如何对账&quot;&gt;如何对账？&lt;/h3&gt;

&lt;p&gt;使用&lt;strong&gt;非对称加密&lt;/strong&gt;的技术&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将交易信息&lt;strong&gt;Hash&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;私钥+Hash值进行签名运算，得到&lt;strong&gt;数字签名&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;交易信息Hash值+交易签名一起&lt;strong&gt;广播&lt;/strong&gt;出去，给全世界的账本&lt;/li&gt;
  &lt;li&gt;接收到信息的其他账本开始进行&lt;strong&gt;验证运算&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;区块链特点&quot;&gt;区块链特点&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;安全&lt;/li&gt;
  &lt;li&gt;匿名化 不受监管&lt;/li&gt;
  &lt;li&gt;不可篡改&lt;/li&gt;
  &lt;li&gt;去中心化&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;关于比特币&quot;&gt;关于比特币&lt;/h2&gt;

&lt;p&gt;任何一个正常的国家都不会允许一种&lt;strong&gt;不受监管的&lt;/strong&gt;、&lt;strong&gt;发行权不在自己手里&lt;/strong&gt;的货币的存在。我国明确规定ICO为非法金融活动，禁止交易所的存在。在美国，交易所对于超过1w的交易需要&lt;strong&gt;实名制&lt;/strong&gt;，执行反洗钱条例，需要向美国的国税局监管部门披露用户的具体信息。&lt;/p&gt;

&lt;p&gt;比特币之所以被人追捧，是因为它的&lt;strong&gt;匿名化&lt;/strong&gt;，&lt;strong&gt;去中心化&lt;/strong&gt;的特点。但它为了生存，却不得不接受&lt;strong&gt;实名制&lt;/strong&gt;和&lt;strong&gt;中心化&lt;/strong&gt;的收编。&lt;/p&gt;
</description>
        <pubDate>Sun, 02 Feb 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/reading/What-is-Block-Chain.html</link>
        <guid isPermaLink="true">http://localhost:4000/reading/What-is-Block-Chain.html</guid>
        
        <category>reading</category>
        
        
        <category>reading</category>
        
      </item>
    
      <item>
        <title>电脑小问题修复总结</title>
        <description>&lt;h2 id=&quot;macos联网后无法同步时间&quot;&gt;macOS联网后无法同步时间&lt;/h2&gt;

&lt;p&gt;电脑一直有待机时耗电严重的问题，前段时间电脑忘记关机保持在待机模式，电池耗尽后系统时间出现了点问题，且联网后无法同步最新时间。&lt;/p&gt;

&lt;p&gt;有人提出使用Linux时间同步命令&lt;code class=&quot;highlighter-rouge&quot;&gt;ntpdate&lt;/code&gt;更新时间，本机提示command not found&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;╰─[:&lt;span class=&quot;o&quot;&gt;)]&lt;/span&gt; % &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;ntpdate 0.centos.pool.ntp.org
Password:
&lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt;: ntpdate: &lt;span class=&quot;nb&quot;&gt;command &lt;/span&gt;not found
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;查询&lt;a href=&quot;https://stackoverflow.com/questions/52548093/ntpdate-command-not-found-macos-mojave&quot;&gt;StackOverflow&lt;/a&gt;得知应使用&lt;code class=&quot;highlighter-rouge&quot;&gt;sntp&lt;/code&gt;命令：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;sntp &lt;span class=&quot;nt&quot;&gt;-sS&lt;/span&gt; time.apple.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;问题解决&lt;/p&gt;

&lt;hr /&gt;

</description>
        <pubDate>Sat, 01 Feb 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/other/%E7%94%B5%E8%84%91%E5%B0%8F%E9%97%AE%E9%A2%98%E4%BF%AE%E5%A4%8D%E6%80%BB%E7%BB%93.html</link>
        <guid isPermaLink="true">http://localhost:4000/other/%E7%94%B5%E8%84%91%E5%B0%8F%E9%97%AE%E9%A2%98%E4%BF%AE%E5%A4%8D%E6%80%BB%E7%BB%93.html</guid>
        
        <category>OTHER</category>
        
        
        <category>other</category>
        
      </item>
    
      <item>
        <title>Plan</title>
        <description>&lt;h2 id=&quot;知识整理计划&quot;&gt;知识整理计划&lt;/h2&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;计算机系统&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;数据结构&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;计算机网络&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;形式语言与自动机&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;软件构造&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;信息安全&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;额外阅读计划&quot;&gt;额外阅读计划&lt;/h2&gt;
</description>
        <pubDate>Sat, 01 Feb 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/reading/Plan.html</link>
        <guid isPermaLink="true">http://localhost:4000/reading/Plan.html</guid>
        
        <category>PLAN</category>
        
        
        <category>reading</category>
        
      </item>
    
      <item>
        <title>🍳主成分分析 PCA</title>
        <description>&lt;h1 id=&quot;-降维&quot;&gt;🍳 降维&lt;/h1&gt;

&lt;h2 id=&quot;主成分分析-principal-component-analysis--pca&quot;&gt;主成分分析 &lt;em&gt;Principal Component Analysis&lt;/em&gt; —— PCA&lt;/h2&gt;

&lt;p&gt;PCA的本质是将$n$维数据投影到$k$维空间中。若存在一个超平面，可以对正交属性空间中的样本点进行恰当的表达，那么这个超平面具有最近重构性和最大可分性。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;最近重构性&lt;/strong&gt;：样本点到这个超平面的距离都足够近&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;最大可分性&lt;/strong&gt;：样本点在这个超平面上的投影尽可能分开&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;从最大可分性证明&quot;&gt;从最大可分性证明&lt;/h2&gt;

&lt;p&gt;​	样本点$\boldsymbol x_i $在新空间中超平面上的投影是$\bf W^T \boldsymbol x_i $，若使所有样本点的投影尽可能分开，则应该使投影后样本点的方差最大化。投影后样本点的方差为$\sum_i \bf W^T \boldsymbol x_i \boldsymbol x_i^T\bf W$，则优化目标和限制条件如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max_{\boldsymbol W} \ \rm{tr}( \bf W^T\bf X \bf X^T\bf W )&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\rm {s.t.}  \bf W^T \bf W = \bf I&lt;/script&gt;

&lt;p&gt;使用拉格朗日乘子法：&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\bf X \bf X^T\bf W = \lambda \bf W&lt;/script&gt;
对协方差矩阵$\boldsymbol X \boldsymbol X^T$进行特征值分解，并将求的的特征值进行排序，取前$k$个最大的特征值对应的特征向量构成投影矩阵$\bf W = {\boldsymbol w_1,\boldsymbol w_2, \dots,\boldsymbol w_k}$&lt;/p&gt;

&lt;p&gt;注：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
{\bf X} =\left[    \begin{matrix}        {\boldsymbol x}^{(1)} - \overline {\bf X}\\        {\boldsymbol x}^{(2)}- \overline {\bf X} \\        \vdots \\        {\boldsymbol x}^{(m)} - \overline {\bf X}   \end{matrix}    \right] =    \left[        \begin{matrix}            x^{(1)}_{1}- \overline {x}_1 &amp; x^{(1)}_{2}- \overline {x}_2   &amp; \cdots &amp; x^{(1)}_{n}- \overline {x}_n   \\            x^{(2)}_{1}- \overline {x}_1 &amp; x^{(2)}_{2} - \overline {x}_2  &amp; \cdots &amp; x^{(2)}_{n}- \overline {x}_n   \\            \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\            x^{(m)}_{1}- \overline {x}_1 &amp; x^{(m)}_{2}- \overline {x}_2 &amp; \cdots &amp; x^{(m)}_{n}- \overline {x}_n        \end{matrix}        \right] %]]&gt;&lt;/script&gt;

&lt;p&gt;故$\boldsymbol X \boldsymbol X^T$为协方差矩阵&lt;/p&gt;

&lt;h2 id=&quot;算法流程&quot;&gt;算法流程&lt;/h2&gt;

&lt;p&gt;给定数据集$D = { \boldsymbol x_1, \boldsymbol x_2, \dots, \boldsymbol x_m}$，对样本进行中心化，即&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol x_i \leftarrow \boldsymbol x_i - \boldsymbol \mu&lt;/script&gt;

&lt;p&gt;其中${\boldsymbol \mu} = \frac{1}{m}\sum\limits_{j = 1}^m{\boldsymbol x}_j$，为数据集的$D$的均值向量。这个步骤相当于平移坐标轴到所有数据点的平均中点位置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/PCA.png&quot; alt=&quot;6&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​	当数据受到噪声影响时，最小的特征值对应的特征向量往往与噪声有关，将它们舍弃在一定程度上起到去噪的效果。&lt;/p&gt;

&lt;h2 id=&quot;信噪比-snr--signal-to-noise-ratio&quot;&gt;信噪比 SNR —— &lt;em&gt;Signal to Noise Ratio&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;信噪比公式如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{SNR} = 10·\log_{10}\left[\frac{\sum\limits_{x=1}^{N_x}\sum\limits_{y=1}^{N_y}\left[f(x,y)\right]^2}{\sum\limits_{x=1}^{N_x}\sum\limits_{y=1}^{N_y}\left[f(x,y)-\hat f(x,y)\right]^2}\right]&lt;/script&gt;

&lt;p&gt;设样本个数为$m$，维数为$n$
&lt;script type=&quot;math/tex&quot;&gt;\hat y = X^T\boldsymbol \theta_0 + \sum_{j=1}^Mc_j·\max
\{0,X^T\boldsymbol \theta_j\}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol \theta = \left[\begin{matrix}     b  \\     \theta_1 \\    \theta_2\\  \vdots\\     \theta_n\end{matrix}\right],
\boldsymbol x = \left[\begin{matrix}   1\\   x_1  \\     x_2 \\       \vdots\\     x_n\end{matrix}\right] \rightarrow f(x)= \boldsymbol \theta^T \boldsymbol x&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
{\boldsymbol \theta} =\left[    
\begin{matrix}        
{\boldsymbol \theta}^{(1)}\\        
{\boldsymbol \theta}^{(2)} \\        
\vdots \\        
{\boldsymbol \theta}^{(M)} 
\end{matrix}    \right] =    
\left[        
\begin{matrix}            
\theta^{(1)}_{1} &amp; \theta^{(1)}_{2}  &amp;\dots&amp; \theta^{(1)}_{n}   \\      

\theta^{(2)}_{1} &amp; \theta^{(2)}_{2}  &amp;\dots&amp; \theta^{(2)}_{n}   \\   
\vdots&amp;\vdots&amp;\ddots&amp;\vdots&amp;\\

\theta^{(M)}_{1} &amp; \theta^{(M)}_{2}  &amp;\dots&amp; \theta^{(M)}_{n}   \\   

\end{matrix}        
\right] 

\boldsymbol X = 
\left[
\begin{matrix}   
1&amp;1&amp;\dots&amp;1\\  
x^{(1)}_1&amp;x^{(2)}_1&amp;\dots&amp;x^{(m)}_1  \\     
x^{(1)}_2&amp;x^{(2)}_2&amp;\dots&amp;x^{(m)}_2 \\       
\vdots\\     
x^{(1)}_n&amp;x^{(2)}_n&amp;\dots&amp;x^{(m)}_n
\end{matrix}

\right]

\\

\boldsymbol \theta \boldsymbol X = 
\left[\begin{matrix}   
 
\boldsymbol \theta^{(1)}\boldsymbol x^{(1)} &amp;
\boldsymbol \theta^{(1)}\boldsymbol x^{(2)} &amp;
\dots &amp;
\boldsymbol \theta^{(1)}\boldsymbol x^{(m)}\\ 

\boldsymbol \theta^{(2)}\boldsymbol x^{(1)} &amp;
\boldsymbol \theta^{(2)}\boldsymbol x^{(2)} &amp;
\dots &amp;
\boldsymbol \theta^{(2)}\boldsymbol x^{(m)}\\    

\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\     
 
\boldsymbol \theta^{(M)}\boldsymbol x^{(1)} &amp;
\boldsymbol \theta^{(M)}\boldsymbol x^{(2)} &amp;
\dots &amp;
\boldsymbol \theta^{(M)}\boldsymbol x^{(m)}\\   
\end{matrix}

\right]
\\
\boldsymbol \theta^{(j)} \boldsymbol x^{(k)} =  \sum  \boldsymbol \theta^{(j)}_i \boldsymbol x^{(k)}_i %]]&gt;&lt;/script&gt;

</description>
        <pubDate>Sun, 24 Nov 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/coding/PCA.html</link>
        <guid isPermaLink="true">http://localhost:4000/coding/PCA.html</guid>
        
        <category>CODE</category>
        
        <category>MACHINELEARNING</category>
        
        
        <category>coding</category>
        
      </item>
    
      <item>
        <title>🐣 SVM推导与总结</title>
        <description>&lt;h2 id=&quot;logistic代价函数推导svm&quot;&gt;Logistic代价函数推导SVM&lt;/h2&gt;

&lt;p&gt;0/1损失函数$l_{0/1}$非凸、非连续，数学性质差，故常用其他函数代替$l_{0/1}$&lt;/p&gt;

&lt;p&gt;三种常用的替代损失函数：
&lt;script type=&quot;math/tex&quot;&gt;l_{hinge}(z) = \max(0,1-z)&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_{exp}(z) = e^{-z}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_{log}(z) = log(1+e^{-z})&lt;/script&gt;

&lt;h3 id=&quot;logistic-regression&quot;&gt;Logistic Regression&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_\theta \frac{1}{m} \left[ \sum_{i=1}^m y^{(i)}\left[-\log(h_{\theta}(x^{(i)}))\right]+(1-y^{(i)})\left[-\log(1-h_{\theta}(x^{(i)}))\right]\right]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_\theta  \left[ \sum_{i=1}^m 
y^{(i)}cost_1
+(1-y^{(i)})cost_0\right] 
+\frac{\lambda}{2}\sum_{j=1}^n\theta_j^2&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A + \lambda B&lt;/script&gt;

&lt;h3 id=&quot;svm&quot;&gt;SVM&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C A + B&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_\theta C  \sum_{i=1}^m\left[ y^{(i)}cost_1(\boldsymbol \theta^T\boldsymbol x^{(i)})+(1-y^{(i)})cost_0({\boldsymbol \theta}^T\boldsymbol x^{(i)})\right]+\frac{1}{2}\sum_{j=1}^n\theta_j^2&lt;/script&gt;

&lt;p&gt;其中SVM中的代价函数$cost$采用$hinge$损失
&lt;script type=&quot;math/tex&quot;&gt;l_{hinge}(z) = \max(0,1-z)&lt;/script&gt;
如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/svm_cost.png&quot; alt=&quot;5&quot; style=&quot;zoom:70%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以直观地发现当$y=1$时，我们希望$\boldsymbol \theta^T\boldsymbol x \gg 1$，这样使$cost_1$最小；当$y=0$时，我们希望$\boldsymbol \theta^T\boldsymbol x \ll -1$，这样使$cost_0$最小。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;margin&quot;&gt;Margin&lt;/h2&gt;

&lt;p&gt;设划分超平面的方程为
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol w^T\boldsymbol x +b =0&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;样本中任意点到该超平面的距离为
&lt;script type=&quot;math/tex&quot;&gt;d = \frac{\boldsymbol w^T x +b}{||\boldsymbol w||}&lt;/script&gt;
对于$y=1$，$y=-1$两类样本点，任意点到超平面的距离应大于$d$
&lt;script type=&quot;math/tex&quot;&gt;\frac{\boldsymbol w^T  x^{(i)} +b}{||\boldsymbol w||} \geq d, \ \forall y^{(i)} = 1\\
\frac{\boldsymbol w^T  x^{(i)} +b}{||\boldsymbol w||} \leq -d, \ \forall y^{(i)} = -1
\\ \Downarrow \\
\frac{\boldsymbol w^T  x^{(i)} +b}{||\boldsymbol w||d} \geq 1, \ \forall y^{(i)} = 1\\
\frac{\boldsymbol w^T  x^{(i)} +b}{||\boldsymbol w||d} \leq -1, \ \forall y^{(i)} = -1
\\ \Downarrow \\
\boldsymbol w_d^T  x^{(i)} +b_d \geq 1, \ \forall y^{(i)} = 1\\
\boldsymbol w_d^T  x^{(i)} +b_d \leq -1, \ \forall y^{(i)} = -1
\\ \Downarrow \\
y^{(i)}(\boldsymbol w^T  x^{(i)} +b) \geq 1&lt;/script&gt;
&lt;img src=&quot;../img/svm_margin.png&quot; style=&quot;zoom:30%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于任意支撑向量，优化目标为最大化点到超平面的距离：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max \frac{|\boldsymbol w^T x +b|}{||\boldsymbol w||} \Rightarrow \max \frac{1}{||\boldsymbol w||}  \Rightarrow \min \frac{1}{2}||w||^2&lt;/script&gt;

&lt;p&gt;则SVM的优化目标为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\boldsymbol w,b} \frac{1}{2}||\boldsymbol w||^2 \\
{\rm{s.t.}} \ \ y^{(i)}(\boldsymbol w^T \boldsymbol x^{(i)}+b)\geq 1, \ i = 1,2,\dots,m.&lt;/script&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;软间隔-soft-margin-svm&quot;&gt;软间隔 Soft Margin SVM&lt;/h2&gt;

&lt;p&gt;非线性可分情况，允许误差$\xi_i$&lt;/p&gt;

&lt;p&gt;L1正则&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\boldsymbol w,b} \frac{1}{2}||\boldsymbol w||^2 + C\sum_{i=1}^m \xi_i\\
{\rm{s.t.}} \ \ y^{(i)}(\boldsymbol w^T \boldsymbol x^{(i)}+b)\geq 1 - \xi_i \\\ i = 1,2,\dots,m,\ \xi_i\geq0&lt;/script&gt;

&lt;p&gt;L2正则&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\boldsymbol w,b} \frac{1}{2}||\boldsymbol w||^2 + C\sum_{i=1}^m \xi_i^2\\
{\rm{s.t.}} \ \ y^{(i)}(\boldsymbol w^T \boldsymbol x^{(i)}+b)\geq 1 - \xi_i \\\ i = 1,2,\dots,m,\ \xi_i\geq0&lt;/script&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;拉格朗日对偶性-lagrangian-duality&quot;&gt;拉格朗日对偶性 Lagrangian Duality&lt;/h2&gt;

&lt;p&gt;​	在约束最优化问题中，常常利用拉格朗日对偶性将原始问题转为对偶问题，通过解决对偶问题而得到原始问题的解。当满足一定条件时，原始问题与对偶问题的解是完全等价的。&lt;/p&gt;

&lt;p&gt;原始目标：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\boldsymbol w,b} \frac{1}{2}||\boldsymbol w||^2&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm{s.t.}} \ \ y^{(i)}(\boldsymbol w^T \boldsymbol x^{(i)}+b)\geq 1, \ i = 1,2,\dots,m.&lt;/script&gt;

&lt;p&gt;使用拉格朗日乘法构造拉格朗日函数转化为无约束优化问题，其中拉格朗日乘子$\alpha_i\geq0$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\boldsymbol w,b, \boldsymbol \alpha) = \frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1-y^{(i)}(\boldsymbol w^T \boldsymbol x^{(i)}+b))&lt;/script&gt;

&lt;p&gt;将$L(\boldsymbol w,b, \boldsymbol \alpha) $看作是关于$\boldsymbol \alpha$的函数，求&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max_{\boldsymbol \alpha} L(\boldsymbol w,b, \boldsymbol \alpha)&lt;/script&gt;

&lt;p&gt;当某个约束条件不满足时，如&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
y^{(i)}(\boldsymbol w^T \boldsymbol x^{(i)}+b)&lt; 1 %]]&gt;&lt;/script&gt;，那么显然有&lt;script type=&quot;math/tex&quot;&gt;\max\limits_{\boldsymbol \alpha} L(\boldsymbol w,b, \boldsymbol \alpha) = \infty&lt;/script&gt;（令&lt;script type=&quot;math/tex&quot;&gt;\alpha_i=\infty&lt;/script&gt;即可）而当所有约束条件都满足时，则最优值为&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{2}\|\boldsymbol w\|^2&lt;/script&gt;，即最初要最小化的目标值。因此，在约束条件得到满足的情况下最小化&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{2}\|\boldsymbol w\|^2&lt;/script&gt;，等同于求&lt;script type=&quot;math/tex&quot;&gt;\max\limits_{\boldsymbol \alpha} L(\boldsymbol w,b, \boldsymbol \alpha)&lt;/script&gt;的最小值。&lt;/p&gt;

&lt;p&gt;原始目标变为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\boldsymbol w,b}\max_{\boldsymbol \alpha} L(\boldsymbol w,b, \boldsymbol \alpha)&lt;/script&gt;

&lt;p&gt;这个问题只有在满足约束条件下才有极小值，也就是说这个问题的极小值一定满足约束条件。&lt;/p&gt;

&lt;p&gt;令$\nabla_\boldsymbol w L = 0$，$\nabla_b L = 0$，得：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol w =\sum_{i=1}^m\alpha_iy_i\boldsymbol x_i&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^m\alpha_iy_i = 0&lt;/script&gt;

&lt;p&gt;将其带入，则原始问题转化对偶问题：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max_\boldsymbol \alpha\sum_{i=1}^m \alpha_i-\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i\alpha_jy_iy_j\boldsymbol x_i\boldsymbol x_j \\&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
{\rm{s.t.}} &amp;\  \sum_{i=1}^m\alpha_iy_i = 0,\\ 
&amp;\ \alpha_i\geq0, \ i = 1,2,\dots,m
\end{align} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;强对偶和弱对偶-strong-and-weak-duality&quot;&gt;强对偶和弱对偶 strong and weak duality&lt;/h3&gt;

&lt;p&gt;原始问题 Primal Problem&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;p^* = \min_w \max_{\alpha_i \geq 0} L(\boldsymbol w,b, \boldsymbol \alpha)&lt;/script&gt;
对偶问题 Dual Problem&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;d^* = \max_{\alpha_i \geq 0}\min_w  L(\boldsymbol w,b, \boldsymbol \alpha)&lt;/script&gt;
弱对偶性：
&lt;script type=&quot;math/tex&quot;&gt;d^* \leq p^*&lt;/script&gt;
强对偶性：
&lt;script type=&quot;math/tex&quot;&gt;d^* = p^*&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;kkt-conditions&quot;&gt;KKT conditions&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;定常方程式 stationary equation&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla_\boldsymbol w L = 0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla_b L = 0&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;原始可行性 primal feasibility&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y^{(i)}(\boldsymbol w^T \boldsymbol x^{(i)}+b)\geq 1&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;对偶可行性 dual feasibility&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_i \geq 0&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;辅松弛 complementary slackness&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_i(y^{(i)}f(x^{(i)})-1)=0&lt;/script&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;核函数-kernel-trick&quot;&gt;核函数 Kernel Trick&lt;/h2&gt;

&lt;p&gt;在&lt;strong&gt;线性不可分&lt;/strong&gt;的情况下，支持向量机首先在低维空间中完成计算，然后通过核函数将输入空间映射到高维特征空间，最终在高维特征空间中构造出最优分离超平面，从而把平面上本身不好分的非线性数据分开——依靠升维使原本线性不可分的数据线性可分&lt;/p&gt;

&lt;p&gt;SVM优化问题经过对偶转化为了&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max_\boldsymbol \alpha\sum_{i=1}^m \alpha_i-\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i\alpha_jy_iy_j\boldsymbol x_i\boldsymbol x_j&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
{\rm{s.t.}} &amp;\  \sum_{i=1}^m\alpha_iy_i = 0,\\ 
&amp;\ \alpha_i\geq0, \ i = 1,2,\dots,m
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;可以看到数据点仅出现为为内积$\boldsymbol x_i\boldsymbol x_j$&lt;/p&gt;

&lt;p&gt;只要能在特征空间中计算出内积，就不需要显式的映射。而且许多常见的几何操作（角度、距离）可以用内积表示。减少计算量和储存空间。&lt;/p&gt;

&lt;p&gt;定义核函数${\rm{K}} (\boldsymbol x_i,\boldsymbol x_j)=\boldsymbol x_i’·\boldsymbol x_j’=(\boldsymbol x_i·\boldsymbol x_j+1)^2$&lt;/p&gt;

&lt;p&gt;核函数本质是将数据添加多项式特征 $x \rightarrow x’$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x'= (x_n^2,\dots,x_1^2,\sqrt2 x_nx_{n-1},\dots,\sqrt2x_n\dots,\sqrt2 x_1,1)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;核函数不是SVM专有&lt;/li&gt;
  &lt;li&gt;存在$\boldsymbol x_i·\boldsymbol x_j$即可应用核函数&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;核函数类型&quot;&gt;核函数类型&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;线性核函数 &lt;em&gt;Linear kernel&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm{K}} (\boldsymbol x_i,\boldsymbol x_j)=\boldsymbol x_i·\boldsymbol x_j&lt;/script&gt;

&lt;ol&gt;
  &lt;li&gt;多项式核函数 &lt;em&gt;Polynomial kernel&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm{K}} (\boldsymbol x_i,\boldsymbol x_j)=(\boldsymbol x_i·\boldsymbol x_j+1)^d&lt;/script&gt;

&lt;ol&gt;
  &lt;li&gt;高斯核函数 /  径向基函数 Radial Basis Function Kernel —— RBF&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm{K}} (\boldsymbol x_i,\boldsymbol x_j)=e^{-\gamma||\boldsymbol x_i-\boldsymbol x_j||^2}&lt;/script&gt;

&lt;p&gt;将每个样本点映射到无穷维的特征空间，每个数据点都是landmark
&lt;script type=&quot;math/tex&quot;&gt;x \rightarrow (e^{-\gamma||\boldsymbol x-\boldsymbol l_1||^2},e^{-\gamma||\boldsymbol x-\boldsymbol l_2||^2})&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m \times n \rightarrow m \times m&lt;/script&gt;

&lt;p&gt;原本$n$维的数据升为$m$维（$m$为数据量）&lt;/p&gt;

&lt;p&gt;应用：自然语言处理&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;svm思想解决回归问题&quot;&gt;SVM思想解决回归问题&lt;/h2&gt;

&lt;p&gt;核心思想：在margin里包含的样本点越多越好&lt;/p&gt;

&lt;p&gt;超参数$\epsilon$指定margin到中间直线的距离&lt;/p&gt;
</description>
        <pubDate>Wed, 20 Nov 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/coding/SVM.html</link>
        <guid isPermaLink="true">http://localhost:4000/coding/SVM.html</guid>
        
        <category>CODE</category>
        
        <category>MACHINELEARNING</category>
        
        
        <category>coding</category>
        
      </item>
    
      <item>
        <title>聚类 Clustering —— K-means &amp; GMM</title>
        <description>&lt;h2 id=&quot;聚类性能度量&quot;&gt;聚类性能度量&lt;/h2&gt;

&lt;p&gt;聚类性能度量：聚类&lt;strong&gt;有效性指标&lt;/strong&gt;——簇内相似度高，簇间相似度低&lt;/p&gt;

&lt;p&gt;衡量指标包括外部指标/内部指标&lt;/p&gt;

&lt;p&gt;定义数据集$D={\boldsymbol x_1,\boldsymbol x_2,…,\boldsymbol x_m}$，通过聚类给出的簇划分为$C={C_1, C_2,…,C_k}$，参考模型给出的簇划分为$C^o={C_1^o, C_2^o,…,C_s^o}$，$\lambda$、$\lambda^o$为对应的簇$C$、$C^o$标记向量 ，其中$\lambda_j$的值表示$\boldsymbol x_j$在第几类，即$\boldsymbol x_j \in C_{\lambda_j}$。将样本两两配对，定义&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
a=|SS|, SS=\{(\boldsymbol{x}_i,\boldsymbol{x}_j)|\lambda_i=\lambda_j,\lambda_i^o=\lambda_j^o,i&lt;j\}\\
b=|SD|, SD=\{(\boldsymbol{x}_i,\boldsymbol{x}_j)|\lambda_i=\lambda_j,\lambda_i^o\neq\lambda_j^o,i&lt;j\}\\
c=|DS|, DS=\{(\boldsymbol{x}_i,\boldsymbol{x}_j)|\lambda_i\neq\lambda_j,\lambda_i^o=\lambda_j^o,i&lt;j\}\\
d=|DD|, DD=\{(\boldsymbol{x}_i,\boldsymbol{x}_j)|\lambda_i\neq\lambda_j,\lambda_i^o\neq\lambda_j^o,i&lt;j\}\\ %]]&gt;&lt;/script&gt;

&lt;p&gt;$SS$包含在$C$、$C^o$中均隶属于相同簇的样本对，$SD$包含在$C$属于同一簇，在$C^o$中隶属于不同簇的样本对。$SS$属于聚类完全正确，$DD$属于聚类结果正确。&lt;/p&gt;

&lt;p&gt;聚类性能度量外部指标：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Jaccard系数 JC&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;JC=\frac{a}{a+b+c}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;FM指数 FMI&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;FMI=\sqrt{\frac{a}{a+b}·\frac{a}{a+c}}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Rand指数 RI&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;RI=\frac{2(a+d)}{m(m-1)}&lt;/script&gt;

&lt;p&gt;结果值在$[0,1]$区间，值越大越好。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;k均值算法-k-means-&quot;&gt;K均值算法 &lt;em&gt;k-means&lt;/em&gt; 🥝&lt;/h2&gt;

&lt;p&gt;最小化平方误差&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E=\sum_{i=1}^k\sum_{\boldsymbol{x}\in C_i}\|\boldsymbol{x}-\boldsymbol{\mu}_i\|_2^2&lt;/script&gt;

&lt;p&gt;其中$\boldsymbol \mu_i=\frac{1}{\vert C_i\vert}\sum_{\boldsymbol x\in C_i}\boldsymbol{x}$ 是簇$C_i$的均值向量(中心)，$E$刻画了簇内样本与中心$\boldsymbol{\mu}_i$的紧密程度。$E$越小，簇内样本相似度越高。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;../img/k-means.png&quot; alt=&quot;6&quot; style=&quot;zoom:60%;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;高斯混合聚类-gaussian-mixture-model--gmm-&quot;&gt;高斯混合聚类 Gaussian Mixture Model —— GMM 🥑&lt;/h2&gt;

&lt;p&gt;高斯分布概率密度：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x)= \frac{1}{\sqrt {2 \pi} \sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}&lt;/script&gt;

&lt;p&gt;多元高斯分布的概率密度函数：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\boldsymbol{x})=\frac{1}{(2\pi)^{\frac{n}{2}}|\boldsymbol{\Sigma}|^{\frac1{2}}}e^{-\frac{1}{2}(\boldsymbol{x}-\boldsymbol\mu)^T\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol\mu)}&lt;/script&gt;

&lt;p&gt;其中$\mu$是$n$维均值向量，$\boldsymbol{\Sigma}$是$n\times n$的协方差矩阵。高斯分布完全由均值向量$\boldsymbol\mu$，协方差矩阵$\boldsymbol{\Sigma}$确定。将概率密度函数记为$p(\boldsymbol{x}\vert\boldsymbol{\mu}_i,\boldsymbol\Sigma_i)$，定义高斯混合分布如下&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_\mathcal{M}(\boldsymbol{x})=\sum_{i=1}^k\alpha_i·p(\boldsymbol{x}|\boldsymbol\mu_i,\boldsymbol{\boldsymbol{\Sigma}}_i)&lt;/script&gt;

&lt;p&gt;高斯混合分布由$k$个&lt;strong&gt;混合成分&lt;/strong&gt;组成，每个混合成分对应一个高斯分布。其中$\mu_i$与$\boldsymbol \Sigma_i$是第$i$个高斯混合成分的参数，$\alpha_i&amp;gt;0$为相应的&lt;strong&gt;混合系数&lt;/strong&gt;，$\sum_{i=1}^k\alpha_i = 1$. 混合系数本质上是第$i$类样本所占整体样本的比例，从另一个角度看则是样本属于第$i$簇的概率。&lt;/p&gt;

&lt;p&gt;使用高斯混合分布的模型在样本空间中生成样本的过程：以$\alpha_1,\alpha_2,…,\alpha_k$作为概率选择出一个混合成分，根据该混合成分的概率密度函数，采样产生出相应的样本。&lt;/p&gt;

&lt;p&gt;给定样本集$D$，可使用&lt;strong&gt;极大似然估计&lt;/strong&gt;，即最大化对数似然函数&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
LL(D) &amp; = \ln \left( \prod \limits_{j=1}^mp_\mathcal{M}(\boldsymbol{x}_j) \right)\\ 
&amp; = \sum \limits_{j=1}^m \ln \sum_{i=1}^k\alpha_i·p(\boldsymbol{x}|\boldsymbol\mu_i, \boldsymbol{\Sigma}_i)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;常用$EM$算法进行迭代优化求解&lt;/p&gt;

&lt;h3 id=&quot;期望最大化-expectation-maximization--em-&quot;&gt;期望—最大化 Expectation-Maximization —— EM 🥭&lt;/h3&gt;

&lt;p&gt;设训练集为$D={\boldsymbol{x}&lt;em&gt;1,\boldsymbol{x}_2,…,\boldsymbol{x}_m}$为高斯混合分布模型生成的样本，设$z_j$表示生成样本 $\boldsymbol{x}_j$的高斯混合成分，即$P(z_j=i)$对应于$\alpha_i(i=1,2,…,k)$。根据&lt;strong&gt;贝叶斯定理&lt;/strong&gt;，$z_j$的后验分布对应样本$\boldsymbol{x}_j$由第$i$个高斯混合分布成分生成的&lt;strong&gt;后验概率&lt;/strong&gt;，简记为$\gamma&lt;/em&gt;{ji}$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\gamma_{ji}= p_\mathcal{M}(z_j=i|\boldsymbol{x}_j) &amp;= \frac{P(z_j=i)·p_\mathcal{M}(\boldsymbol{x}_j|z_j=i)}{p_\mathcal{M}(\boldsymbol{x}_j)} \\
&amp; = \frac{\alpha_i·p(\boldsymbol{x}_j|\boldsymbol\mu_i,\boldsymbol\Sigma_i)}{\sum\limits_{l=1}^k\alpha_l·p(\boldsymbol{x}_j|\boldsymbol\mu_l,\boldsymbol\Sigma_l)}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;$\gamma_{ji}$是已知样本为$\boldsymbol{x}_j$，反推该样本属于第$i$类的概率。把$\boldsymbol{x}_j$暂时划分到概率最大的那一类，则样本$\boldsymbol{x}_j$的簇标记$\lambda_j$为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lambda_j = \mathop{\arg\max} \limits_{i\in{1,2,...,k}} \gamma_{ji}&lt;/script&gt;

&lt;p&gt;若参数${(\alpha_i,\boldsymbol\mu_i,\boldsymbol{\Sigma}_i)}$能使似然函数最大化，由$\frac{\partial LL(D)}{\partial \boldsymbol\mu_i}= 0$有&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol \mu_i = \frac{\sum \limits_{j=1}^m \gamma_{ji} \boldsymbol x_j}{\sum \limits_{j=1}^m \gamma_{ji}} \tag{1}&lt;/script&gt;

&lt;p&gt;由$\frac{\partial LL(D)}{\partial \boldsymbol\Sigma_i}= 0$有&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf\Sigma_{i}=\cfrac{\sum \limits_{j=1}^m\gamma_{ji}(\boldsymbol x_{j}-\boldsymbol \mu_{i})(\boldsymbol x_{j}-\boldsymbol\mu_{i})^T}{\sum \limits_{j=1}^m\gamma_{ji}}\tag{2}&lt;/script&gt;

&lt;p&gt;每个高斯成分的混合系数由该成分的平均后验概率确定&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_i=\frac{1}{m}\sum \limits_{j=1}^m \gamma_{ji}\tag{3}&lt;/script&gt;

&lt;p&gt;EM算法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;E步：根据当前参数计算属于每个高斯成分的后验概率$\gamma_{ji}$&lt;/li&gt;
  &lt;li&gt;M步：根据$(1)(2)(3)$更新${(\alpha_i,\boldsymbol\mu_i,\boldsymbol{\Sigma}_i)\vert1\leq i \leq k}$&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;../img/GMM.png&quot; style=&quot;zoom:60%;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;初始化方案：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;协方差矩阵$\boldsymbol{\Sigma}_i$设为单位矩阵，每个模型比例的先验概率$\alpha_i = 1/k$，均值$\boldsymbol\mu_i$设为随机数&lt;/li&gt;
  &lt;li&gt;由k-means聚类算法对样本进行聚类，利用各类的均值作为$\boldsymbol\mu_i$，并计算$\boldsymbol{\Sigma}_i$，$\alpha_i$取各类样本占样本总数的比例&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 20 Nov 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/coding/%E8%81%9A%E7%B1%BB-Clustering-K-means-&-GMM.html</link>
        <guid isPermaLink="true">http://localhost:4000/coding/%E8%81%9A%E7%B1%BB-Clustering-K-means-&-GMM.html</guid>
        
        <category>CODE</category>
        
        <category>MACHINELEARNING</category>
        
        
        <category>coding</category>
        
      </item>
    
      <item>
        <title>🌲 决策树</title>
        <description>&lt;p&gt;构建决策树之通常包括三个步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;特征选择&lt;/li&gt;
  &lt;li&gt;决策树生成&lt;/li&gt;
  &lt;li&gt;决策树剪枝&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;决策树生成&quot;&gt;决策树生成&lt;/h2&gt;

&lt;h3 id=&quot;信息增益&quot;&gt;信息增益&lt;/h3&gt;

&lt;p&gt;通常使用&lt;strong&gt;信息熵&lt;/strong&gt;Information Entropy度量样本集合纯度。样本集合为$D$，第$k$类样本所占比例为$p_k(k=1,2,…,N)$，则样本$D$的信息熵为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(D) =-\sum\limits_{k=1}^{N}p_k{\log}_2p_k&lt;/script&gt;

&lt;p&gt;$Ent(D)$越小，$D$的纯度越高。&lt;/p&gt;

&lt;p&gt;设离散属性$a$有$V$个可能的取值，当用属性$a$对样本集合$D$进行划分所获的的&lt;strong&gt;信息增益&lt;/strong&gt;Information Gain为目标类变量与属性&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;变量在&lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt;(样本集)上的&lt;strong&gt;互信息&lt;/strong&gt;。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Gain(D,a)=H(D)- \sum \limits_{v=1}^V\frac{|D^v|}{|D|}H(D^v)&lt;/script&gt;

&lt;p&gt;一般而言，信息增益越大，意味着使用属性$a$进行划分获得的纯度提升越大。&lt;/p&gt;

&lt;p&gt;ID3选择属性使用信息增益&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a_* = \mathop{ \arg \max}\limits_{a \in A} Gain(D,a)&lt;/script&gt;

&lt;h3 id=&quot;增益率&quot;&gt;增益率&lt;/h3&gt;

&lt;p&gt;信息增益更偏好于&lt;strong&gt;可取更多的值属性&lt;/strong&gt;，为减小这种偏好的影响，在C4.5选择属性使用&lt;strong&gt;增益率&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Gain\_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}&lt;/script&gt;

&lt;p&gt;$IV(a)$为属性$a$的&lt;strong&gt;固有值&lt;/strong&gt;Intrinsic Value。属性$a$可取值越多，$IV(a)$的值通常会越大。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;IV(a)=-\sum \limits_{v=1}^V\frac{|D^v|}{|D|}\log_2\frac{|D^v|}{|D|}&lt;/script&gt;

&lt;p&gt;个人理解$IV(a)$即计算按属性$a$分类时的信息熵，属性$a$多时混乱程度通常更大，导致信息增益更大。&lt;/p&gt;

&lt;p&gt;C4.5先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择信息增益率最高的。&lt;/p&gt;

&lt;h3 id=&quot;基尼指数&quot;&gt;基尼指数&lt;/h3&gt;

&lt;p&gt;CART决策树使用&lt;strong&gt;基尼指数&lt;/strong&gt;选择划分属性，数据集$D$的纯度可用&lt;strong&gt;基尼值&lt;/strong&gt;度量&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Gini(D)=\sum_{k=1}^N\sum_{k'\neq k}p_kp_{k'} = 1-\sum_{k=1}^N p_k^2&lt;/script&gt;

&lt;p&gt;直观来说，$Gini(D)$反映了从数据集$D$中随机抽取两个样本，其类别标记不一致的概率，因此$Gini(D)$越小，则数据集$D$纯度越高。&lt;/p&gt;

&lt;p&gt;$Gini$在节点取值分布均匀时取最大值$1-1/V$，在只包含一个类别时取最小值$0$。
属性$a$的基尼指数定义为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;𝐺𝑖𝑛𝑖\_𝑖𝑛𝑑𝑒𝑥(𝐷,𝑎)=\sum \limits_{𝑣=1}^𝑉\frac{|D^v|}{|D|}𝐺𝑖𝑛𝑖(𝐷^𝑣)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a_* = \mathop{ \arg \min}\limits_{a \in A} Gini\_index(D,a)&lt;/script&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;决策树剪枝&quot;&gt;决策树剪枝&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;剪枝&lt;/strong&gt;pruning是决策树学习算法中避免过拟合的主要手段。&lt;/p&gt;

&lt;h3 id=&quot;预剪枝&quot;&gt;预剪枝&lt;/h3&gt;

&lt;p&gt;​		在决策树生成过程中，对每个结点划分前进行估计，若对此结点划分不能带来决策树泛化性能的提升，则停止划分并标记为叶子结点。&lt;/p&gt;

&lt;p&gt;​		预剪枝使得决策树的很多分支都没有展开，这不仅降低了过拟合的风险，还显著减少了决策树训练和预测的时间开销。&lt;/p&gt;

&lt;p&gt;​		但是另一方面，有些分支的当前划分虽然不能带来泛化性能的提升，甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致泛化性能显著上升。所以基于贪心策略的预剪枝可能带来欠拟合的风险。&lt;/p&gt;

&lt;h3 id=&quot;后剪枝&quot;&gt;后剪枝&lt;/h3&gt;

&lt;p&gt;首先生成完整的决策树，然后自下而上地逐层剪枝，如果一个节点的子节点被删除后，决策树的准确度没有降低，那么就将该节点设置为叶节点。训练时间开销大。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;连续和缺失值&quot;&gt;连续和缺失值&lt;/h2&gt;

&lt;h3 id=&quot;属性值连续&quot;&gt;属性值连续&lt;/h3&gt;

&lt;p&gt;对于连续的属性而言，属性值可取分界点后构成二分法的分类。分界点的取值同样是两点的中点值，对中点值进行分类增益计算后再进行比较。连续值在子节点上依然能够再次进行分类。&lt;/p&gt;

&lt;h3 id=&quot;样本值缺失&quot;&gt;样本值缺失&lt;/h3&gt;

&lt;p&gt;对于训练决策树时训练集存在某些特征的属性值缺失的情况，会遇到如下两个问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如何选择最优属性进行划分&lt;/li&gt;
  &lt;li&gt;给定划分属性，若在该属性上值缺失，如何确定样本的归属&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于问题1而言：只要将所有的计算换成无缺样本的数据即可。最终增益乘以对应特征所含有值的概率值，&lt;/p&gt;

&lt;p&gt;对于问题2而言：将缺失值的样本按照一定的比例以不同的概率划分到不同的子节点中去。若取值已知，则划分到对应的子节点中去，样本权值在子节点中保持为wx，若取值未知，则将x同时划入所有的子节点中区，并将样本去找你之在对应中调整为对应的比例乘以wx，权重在之后则以概率的形式体现到计算中去。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;多变量决策树&quot;&gt;多变量决策树&lt;/h2&gt;

&lt;p&gt;多变量决策树的学习过程中，不是为每个非叶节点寻找一个最优划分属性，而是试图建立一个合适的线性分类器于一个节点中，减缓决策树的复杂度。&lt;/p&gt;
</description>
        <pubDate>Sun, 10 Nov 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/coding/%E5%86%B3%E7%AD%96%E6%A0%91.html</link>
        <guid isPermaLink="true">http://localhost:4000/coding/%E5%86%B3%E7%AD%96%E6%A0%91.html</guid>
        
        <category>CODE</category>
        
        <category>MACHINELEARNING</category>
        
        
        <category>coding</category>
        
      </item>
    
  </channel>
</rss>
